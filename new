# Environment variables (example)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_KEY=your-service-role-key
OPENAI_API_KEY=your-openai-key (optional, for AI features)
# User Manual - Deploying the Recreated App (Detailed)

1) Supabase setup
   - Sign up at https://supabase.com, Create new project (free tier)
   - From Project > SQL Editor, paste and run supabase_schema.sql
   - From Project > Settings > API, copy the URL and Service Role Key
2) GitHub repo
   - Create a new repo (private if you prefer) and push this project's files
3) Deploy to Netlify (recommended)VITE_API_BASE=http://localhost:4000

FROM node:18-alpine
WORKDIR /app
COPY package.json package-lock.json* ./import React, { useEffect, useState } from 'react';
import axios from 'axios';
import Chatbot from './components/Chatbot';
import './styles.css';
const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'DELETE') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const params = event.queryStringParameters || {};
    const id = params.id;
    const token = (event.headers && (event.headers.authorization || event.headers.Authorization)) || params.token;
    if (!token) return { statusCode: 401, body: package.jsonpackage.json({ error: 'Unauthorized' }) };
    const sess = await supabase.from('sessions').select('*').eq('id', token).limit(1).single();
    if (!sess.data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid token' }) };
    const user_id = sess.data.user_id;
    const { data, error } = await supabase.from('entries').delete().eq('id', id).eq('user_id', user_id).select();
    if (error) return { statusCode: 400, body: package.json({ error: error.message }) };
    return { statusCode: 200, body: package.json({ success: true }) };
  } catch (err) {
    return { statusCode: 500, body: package.json({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'GET') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const token = event.headers && (event.headers.authorization || event.headers.Authorization) || (event.queryStringParameters && event.queryStringParameters.token);
    if (!token) return { statusCode: 401, body: JSON.stringify({ error: 'Unauthorized' }) };

    const sess = await supabase.from('sessions').select('*').eq('id', token).limit(1).single();
    if (!sess.data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid token' }) };
    const user_id = sess.data.user_id;

    const { data, error } = await supabase.from('entries').select('*').eq('user_id', user_id).order('created_at', { ascending: false });
    if (error) return { statusCode: 400, body: JSON.stringify({ error: error.message }) };
    return { statusCode: 200, body: JSON.stringify({ entries: data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'GET') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const id = (event.queryStringParameters && event.queryStringParameters.id) || null;
    if (!id) return { statusCode: 400, body: JSON.stringify({ error: 'Missing id' }) };
    const { data, error } = await supabase.from('entries').select('*').eq('id', id).limit(1).single();
    if (error || !data) return { statusCode: 404, body: JSON.stringify({ error: 'Not found' }) };
    return { statusCode: 200, body: JSON.stringify({ entry: data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

exports.handler = async () => ({ statusCode: 200, body: JSON.stringify({ status: 'ok' }) });

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'GET') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const token = (event.queryStringParameters && event.queryStringParameters.token) || null;
    if (!token) return { statusCode: 400, body: JSON.stringify({ error: 'Missing token' }) };
    const { data, error } = await supabase.from('shares').select('*').eq('id', token).limit(1).single();
    if (error || !data) return { statusCode: 404, body: JSON.stringify({ error: 'Not found' }) };
    // fetch entry
    const entry = await supabase.from('entries').select('*').eq('id', data.entry_id).limit(1).single();
    return { statusCode: 200, body: JSON.stringify({ share: data, entry: entry.data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    // This is a stub. Integrate your AI provider (OpenAI) here by using OPENAI_API_KEY env var.
    const sample = { verdict: 'ok', suggestions: ['Keep this', 'Consider improving metadata'] };
    return { statusCode: 200, body: JSON.stringify({ result: sample }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    const { token, title, content, metadata } = body;
    if (!token) return { statusCode: 401, body: JSON.stringify({ error: 'Unauthorized' }) };

    // lookup session
    const sess = await supabase.from('sessions').select('*').eq('id', token).limit(1).single();
    if (!sess.data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid token' }) };
    const user_id = sess.data.user_id;

    const id = uuidv4();
    const { data, error } = await supabase.from('entries').insert([{ id, user_id, title, content, metadata }]).select().single();
    if (error) return { statusCode: 400, body: JSON.stringify({ error: error.message }) };
    return { statusCode: 200, body: JSON.stringify({ entry: data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    const { email, password } = body;
    if (!email || !password) return { statusCode: 400, body: JSON.stringify({ error: 'Email and password required' }) };

    const { data, error } = await supabase.from('users').select('*').eq('email', email).limit(1).single();
    if (error || !data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid credentials' }) };

    const valid = bcrypt.compareSync(password, data.password_hash || '');
    if (!valid) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid credentials' }) };

    // simple session token (for demo); in production use JWT or Supabase Auth
    const token = uuidv4();
    // store token in sessions table (upsert)
    await supabase.from('sessions').upsert({ id: token, user_id: data.id }).select();

    return { statusCode: 200, body: JSON.stringify({ token, user: { id: data.id, email: data.email, name: data.name } }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    const { token, entry_id, expires_in_hours } = body;
    if (!token) return { statusCode: 401, body: JSON.stringify({ error: 'Unauthorized' }) };
    const sess = await supabase.from('sessions').select('*').eq('id', token).limit(1).single();
    if (!sess.data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid token' }) };
    const user_id = sess.data.user_id;

    // verify entry belongs to user
    const entry = await supabase.from('entries').select('*').eq('id', entry_id).limit(1).single();
    if (!entry.data) return { statusCode: 404, body: JSON.stringify({ error: 'Entry not found' }) };

    const token_share = uuidv4();
    const expires_at = new Date(Date.now() + (parseInt(expires_in_hours||24) * 3600 * 1000)).toISOString();
    const { data, error } = await supabase.from('shares').insert([{ id: token_share, entry_id, owner_id: user_id, expires_at }]).select().single();
    if (error) return { statusCode: 400, body: JSON.stringify({ error: error.message }) };
    return { statusCode: 200, body: JSON.stringify({ share: data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'POST') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    const { email, password, name } = body;
    if (!email || !password) return { statusCode: 400, body: JSON.stringify({ error: 'Email and password required' }) };

    // Hash password
    const salt = bcrypt.genSaltSync(10);
    const hash = bcrypt.hashSync(password, salt);
    const id = uuidv4();

    const { data, error } = await supabase.from('users').insert([{ id, email, password_hash: hash, name }]).select().single();
    if (error) {
      return { statusCode: 400, body: JSON.stringify({ error: error.message }) };
    }
    return { statusCode: 200, body: JSON.stringify({ user: { id: data.id, email: data.email, name: data.name } }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

const { createClient } = require('@supabase/supabase-js');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');

const SUPABASE_URL = process.env.SUPABASE_URL;
const SUPABASE_KEY = process.env.SUPABASE_SERVICE_KEY;
if (!SUPABASE_URL || !SUPABASE_KEY) {
  console.warn('SUPABASE_URL or SUPABASE_SERVICE_KEY not set in environment.');
}
const supabase = createClient(SUPABASE_URL, SUPABASE_KEY);


exports.handler = async (event) => {
  if (event.httpMethod !== 'PUT') return { statusCode: 405, body: 'Method Not Allowed' };
  try {
    const body = JSON.parse(event.body || '{}');
    const { token, id, title, content, metadata } = body;
    if (!token) return { statusCode: 401, body: JSON.stringify({ error: 'Unauthorized' }) };
    const sess = await supabase.from('sessions').select('*').eq('id', token).limit(1).single();
    if (!sess.data) return { statusCode: 401, body: JSON.stringify({ error: 'Invalid token' }) };
    const user_id = sess.data.user_id;

    const { data, error } = await supabase.from('entries').update({ title, content, metadata }).eq('id', id).eq('user_id', user_id).select().single();
    if (error) return { statusCode: 400, body: JSON.stringify({ error: error.message }) };
    return { statusCode: 200, body: JSON.stringify({ entry: data }) };
  } catch (err) {
    return { statusCode: 500, body: JSON.stringify({ error: String(err) }) };
  }
};

function Nav({ onRoute, route }){
  return (
    <nav className="nav">
      <div className="logo">NoCodeAI</div>
      <div className="nav-links">
        <button onClick={()=>onRoute('dashboard')} className={route==='dashboard'?'active':''}>Dashboard</button>
        <button onClick={()=>onRoute('entries')} className={route==='entries'?'active':''}>Entries</button>
        <button onClick={()=>onRoute('new')} className={route==='new'?'active':''}>New Entry</button>
        <button onClick={()=>onRoute('admin')} className={route==='admin'?'active':''}>Admin</button>
      </div>
    </nav>
  )
}

function Onboarding({ onClose }){
  return (
    <div className="onboard">
      <h2>Welcome — Quick tour</h2>
      <ol>
        <li>Create entries with text, numbers and file uploads.</li>
        <li>Use the AI assistant on the right to ask how to use features.</li>
        <li>Share entries via secure links and export CSVs.</li>
      </ol>
      <button onClick={onClose}>Got it</button>
    </div>
  )
}

export default function App(){
  // listen for assistant actions
  window.addEventListener('goto', (e)=>{ if (e && e.detail) setRoute(e.detail); });

  const [health, setHealth] = useState('...');
  const [route, setRoute] = useState('dashboard');
  const [token, setToken] = useState(localStorage.getItem('token')||'');
  const [entries, setEntries] = useState([]);
  const [showOnboard, setShowOnboard] = useState(true);

  useEffect(()=> {
    axios.get((import.meta.env.VITE_API_BASE) || 'http://localhost:4000/health')
      .then(r=> setHealth(JSON.stringify(r.data)))
      .catch(e=> setHealth('offline'));
    if (token) fetchEntries();
  }, [token]);

  const fetchEntries = async ()=>{
    try{
      const resp = await axios.get((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/entries', { headers: { Authorization: `Bearer ${token}` } });
      setEntries(resp.data);
    }catch(e){ console.log('fetch entries error', e); }
  };

  const fakeLogin = async () => {
    try {
      const resp = await axios.post((import.meta.env.VITE_API_BASE || 'http://localhost:4000') + '/login', { email: 'karl@example.com', password: 'password' });
      setToken(resp.data.token); localStorage.setItem('token', resp.data.token);
      alert('Demo logged in as ' + resp.data.user.email);
      fetchEntries();
    } catch(e){
      alert('Login failed: ' + (e.response?.data?.error || e.message));
    }
  };

  const logout = ()=>{ setToken(''); localStorage.removeItem('token'); setEntries([]); }

  return (
    <div>
      <Nav onRoute={setRoute} route={route} />
      <div className="container">
        <main className="main">
          <header className="header">
            <h1>No-code AI App</h1>
            <div className="meta">Backend: {health} { token ? <button onClick={logout}>Logout</button> : <button onClick={fakeLogin}>Demo Login</button> }</div>
          </header>

          {route === 'dashboard' && (
            <section>
              <h2>Dashboard</h2>
              <div className="cards">
                <div className="card">Projects<br/><strong>1</strong></div>
                <div className="card">Entries<br/><strong>{entries.length}</strong></div>
                <div className="card">Shared Links<br/><strong>—</strong></div>
              </div>
              <p>Use the AI assistant to learn features or click "Entries" to manage data.</p>
            </section>
          )}

          {route === 'entries' && (
            <section>
              <h2>Entries</h2>
              <div className="entries-list">
                {entries.map(e=> (
                  <div key={e.id} className="entry-card">
                    <h4>{e.title}</h4>
                    <p>Metric: {e.numericMetric1} — Status: {e.status}</p>
                    <div className="entry-actions">
                      <button onClick={async ()=>{ const resp = await axios.get((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/entries/'+e.id, { headers:{ Authorization:`Bearer ${token}` }}); alert(JSON.stringify(resp.data.entry, null, 2)) }}>Open</button>
                      <button onClick={async ()=>{ if (!confirm('Delete?')) return; await axios.delete((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/entries/'+e.id, { headers:{ Authorization:`Bearer ${token}` }}); fetchEntries(); }}>Delete</button>
                      <button onClick={async ()=>{ const r = await axios.post((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/share/create', { entryId: e.id }, { headers:{ Authorization:`Bearer ${token}` }}); alert('Share token: '+ r.data.token + '\nPublic URL: ' + window.location.origin + '/share/' + r.data.token) }}>Share</button>
                    </div>
                  </div>
                ))}
              </div>
            </section>
          )}

          {route === 'new' && (
            <section>
              <h2>New Entry</h2>
              <form onSubmit={async (ev)=>{ ev.preventDefault(); const form=ev.target; const fd=new FormData(); fd.append('title', form.title.value); fd.append('dataFields', form.dataFields.value); fd.append('numericMetric1', form.numericMetric1.value); if (form.file.files[0]) fd.append('file', form.file.files[0]); try{ const resp = await fetch((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/entries/upload', { method:'POST', headers: { Authorization: token ? `Bearer ${token}` : '' }, body: fd }); const j = await resp.json(); alert('Created: ' + (j.entry ? j.entry.id : 'ok') + '\nFile hash: ' + (j.fileHash||'n/a')); fetchEntries(); setRoute('entries'); }catch(err){ alert('Error: '+ err.message) } }}>
                <input name="title" placeholder="Title" required />
                <input name="numericMetric1" placeholder="Metric" type="number" />
                <textarea name="dataFields" placeholder='{"field":"value"}'></textarea>
                <input type="file" name="file" />
                <div style={{display:'flex',gap:8}}><button type="submit">Upload & Create</button><button type="button" onClick={()=>{ window.open((import.meta.env.VITE_API_BASE||'http://localhost:4000') + '/export/csv','_blank') }}>Export CSV</button></div>
              </form>
            </section>
          )}

          {route === 'admin' && (
            <section>
              <h2>Admin</h2>
              <p>Save default schema and manage users (demo).</p>
              <button onClick={async ()=>{ try{ const js = {fields:[{id:'title',label:'Title',type:'text'},{id:'dataFields',label:'Data',type:'textarea'},{id:'numericMetric1',label:'Metric',type:'number'}]}; await axios.post((import.meta.env.VITE_API_BASE||'http://localhost:4000')+'/admin/schema', js, { headers:{ Authorization:`Bearer ${token}` } }); alert('Saved'); }catch(e){ alert('error') } }}>Save Default Schema</button>
            </section>
          )}

        </main>
        <aside className="aside">
          <div className="assistant">
            <h4>AI Assistant</h4>
            <Chatbot apiBase={import.meta.env.VITE_API_BASE || 'http://localhost:4000'} token={token} />
          </div>
        </aside>
      </div>

      {showOnboard && <div className="overlay"><Onboarding onClose={()=>setShowOnboard(false)} /></div>}
    </div>
  )
}

import React from 'react';
import { createRoot } from 'react-dom/client';
import App from './App';

const root = createRoot(document.getElementById('root'));
root.render(<App />);

:root{--bg:#f6f9fb;--accent:#0ea5e9;--card:#fff}
body{margin:0;font-family:Inter,system-ui,Segoe UI,Roboto,Arial,Helvetica,sans-serif;background:var(--bg);color:#0f172a}
.nav{display:flex;justify-content:space-between;align-items:center;padding:12px 24px;background:linear-gradient(90deg,#0ea5e9,#60a5fa);color:white}
.nav .logo{font-weight:700}
.nav .nav-links button{margin-left:8px;padding:8px 12px;border-radius:8px;border:none;background:rgba(255,255,255,0.12);color:white}
.container{display:grid;grid-template-columns:1fr 360px;gap:20px;padding:24px}
.main{min-height:80vh}
.header{display:flex;justify-content:space-between;align-items:center}
.cards{display:flex;gap:12px;margin:12px 0}
.card{background:var(--card);padding:16px;border-radius:12px;box-shadow:0 6px 18px rgba(2,6,23,0.06)}
.entries-list{display:grid;grid-template-columns:repeat(auto-fit,minmax(220px,1fr));gap:12px}
.entry-card{background:var(--card);padding:12px;border-radius:10px;box-shadow:0 3px 10px rgba(2,6,23,0.04)}
.entry-actions button{margin-right:6px}
.aside{padding:12px}
.assistant{position:sticky;top:20px}
.onboard{background:var(--card);padding:20px;border-radius:12px;max-width:640px;margin:40px auto;box-shadow:0 8px 28px rgba(2,6,23,0.08)}
.overlay{position:fixed;left:0;top:0;right:0;bottom:0;background:rgba(2,6,23,0.4);display:flex;align-items:center;justify-content:center;padding:20px}
@media(max-width:900px){.container{grid-template-columns:1fr;}.nav .nav-links{display:none}}

RUN npm install
COPY . .
RUN npm run build
EXPOSE 3000
RUN npm install -g serve
CMD ["serve", "-s", "dist", "-l", "3000"]

<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>No-code Prototype Frontend</title>
</head>
<body>
  <div id="root"></div>
  <script type="module" src="/src/main.jsx"></script>
</body>
</html>

{
  "name": "no-code-prototype-frontend",
  "version": "0.1.0",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "axios": "^1.4.0"
  },
  "devDependencies": {
    "vite": "^5.0.0"
  }
}
   - Sign up at https://netlify.com and 'New site from Git'
   - Connect your GitHub repo and choose branch (main)
   - In Site settings > Build & deploy > Environment, add SUPABASE_URL and SUPABASE_SERVICE_KEY/*
  blockchain_anchor.js - stub to anchor data hash to Ethereum/* Integration snippet for server.js (copy and paste where appropriate)

// at top of server.js/*
  presigned_s3.js - generates S3 presigned PUT URLs for frontend direct uploads/*
  s3_notarize.js - helper functions for S3 uploads and IPFS notarization.

  Usage: require this module from server.js and call uploadToS3(buffer, filename, mimetype)
  or notarizeMetadata(metadata) to pin to Pinata/web3.storage. Set env vars as described in .env.example.
*/

const { S3Client, PutObjectCommand, GetObjectCommand } = require('@aws-sdk/client-s3');
const fetch = global.fetch || require('node-fetch');

function createS3Client() {
  if (!process.env.AWS_ACCESS_KEY_ID || !process.env.AWS_SECRET_ACCESS_KEY || !process.env.AWS_S3_BUCKET) {
    throw new Error('S3 env vars not configured');
  }
  return new S3Client({ region: process.env.AWS_REGION || 'us-east-1', credentials: { accessKeyId: process.env.AWS_ACCESS_KEY_ID, secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY } });
}

async function uploadToS3(buffer, key, contentType) {
  const s3 = createS3Client();
  const cmd = new PutObjectCommand({ Bucket: process.env.AWS_S3_BUCKET, Key: key, Body: buffer, ContentType: contentType });
  await s3.send(cmd);
  // Return s3:// path; you can also create and return pre-signed URL if needed (requires @aws-sdk/s3-request-presigner)
  return `s3://${process.env.AWS_S3_BUCKET}/${key}`;
}

async function notarizeMetadataPinata(metadata) {
  if (!process.env.IPFS_API_KEY) throw new Error('IPFS_API_KEY not set');
  // Example for Pinata JWT method
  const resp = await fetch('https://api.pinata.cloud/pinning/pinJSONToIPFS', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${process.env.IPFS_API_KEY}` },
    body: JSON.stringify({ pinataContent: metadata })
  });
  if (!resp.ok) {
    const txt = await resp.text();
    throw new Error('Pinata failed: ' + txt);
  }
  const jr = await resp.json();
  return jr; // includes IpfsHash
}

module.exports = { uploadToS3, notarizeMetadataPinata };

*/
const { S3Client, PutObjectCommand } = require('@aws-sdk/client-s3');
const { getSignedUrl } = require('@aws-sdk/s3-request-presigner');

function createS3Client() {
  if (!process.env.AWS_ACCESS_KEY_ID || !process.env.AWS_SECRET_ACCESS_KEY || !process.env.AWS_S3_BUCKET) {
    throw new Error('S3 env vars not configured');
  }
  return new S3Client({ region: process.env.AWS_REGION || 'us-east-1', credentials: { accessKeyId: process.env.AWS_ACCESS_KEY_ID, secretAccessKey: process.env.AWS_SECRET_ACCESS_KEY } });
}

/**
 * Generates presigned PUT URL for frontend upload
 * @param {string} key file key in S3
 * @param {string} contentType MIME type
 */
async function generatePresignedPutUrl(key, contentType) {
  const s3 = createS3Client();
  const command = new PutObjectCommand({
    Bucket: process.env.AWS_S3_BUCKET,
    Key: key,
    ContentType: contentType
  });
  return await getSignedUrl(s3, command, { expiresIn: 3600 }); // 1 hour
}

module.exports = { generatePresignedPutUrl };

const { uploadToS3, notarizeMetadataPinata } = require('./extensions/s3_notarize');

// inside /entries/upload handler after computing fileHash and filename:
if (USE_S3) {
  const key = 'uploads/' + filename;
  await uploadToS3(file.buffer, key, file.mimetype);
  attachmentPath = `s3://${process.env.AWS_S3_BUCKET}/${key}`;
}

// after creating entry and storing filehash, optionally call notarize:
if (process.env.IPFS_API_KEY) {
  const metadata = { entryId: entry.id, filename: file.originalname, sha256: fileHash, createdAt: new Date().toISOString() };
  try {
    const pin = await notarizeMetadataPinata(metadata);
    console.log('Pinned to IPFS', pin);
  } catch(err){ console.error('Notarize failed', err) }
}

*/
  Note: requires web3.js or ethers.js and a funded wallet
*/
async function anchorToEthereum(hash, options) {
  // options: { network, privateKey, rpcUrl, contractAddress }
  console.log('Stub: anchoring hash', hash, 'to Ethereum', options.network);
  // Implementation left as exercise; emits tx hash when done
  return '0xFAKE_TRANSACTION_HASH_FOR_DEMO';
}

module.exports = { anchorToEthereum };

   - Set Build command to `npm install && npm run build` if frontend is React; Publish directory to `frontend/build`
   - In Functions settings, ensure functions folder is `functions`# Final Free Version v2 - Recreated App

This package contains a working serverless backend (best-effort) using Supab# Copy to .env and set values
PORT=4000
DB_PATH=./data/app.db
JWT_SECRET=your_jwt_secret_here
OPENAI_API_KEY=sk-REPLACE_WITH_YOUR_KEY
# OWNER: Karl-Heinz - this deployment is intended for exclusive use by the owner

FROM node:18-alpine
WORKDIR /app
COPY package.json package-lock.json* ./
RUN npm install --production
COPY . .
RUN npm run migrate
EXPOSE 4000
CMD ["npm", "start"]

// Migrate script to create SQLite schema
const Database = require('better-sqlite3');
const db = new Database(process.env.DB_PATH || './data/app.db');

db.exec(`
CREATE TABLE IF NOT EXISTS users (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  email TEXT UNIQUE,
  fullName TEXT,
  passwordHash TEXT,
  role TEXT,
  createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
);
CREATE TABLE IF NOT EXISTS projects (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT,
  owner INTEGER,
  description TEXT,
  tags TEXT,
  createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
);
CREATE TABLE IF NOT EXISTS entries (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  projectId INTEGER,
  submittedBy INTEGER,
  title TEXT,
  dataFields TEXT,
  numericMetric1 REAL,
  attachment TEXT,
  status TEXT,
  ai_summary TEXT,
  createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
);
CREATE TABLE IF NOT EXISTS sharinglinks (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      entryId INTEGER,
      token TEXT,
      expiresAt DATETIME,
      accessLevel TEXT
    );
    CREATE TABLE IF NOT EXISTS filehashes (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      entryId INTEGER,
      filename TEXT,
      filepath TEXT,
      sha256 TEXT,
      createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
    );
    CREATE TABLE IF NOT EXISTS schemas (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      name TEXT,
      jsonschema TEXT,
      createdAt DATETIME DEFAULT CURRENT_TIMESTAMP
    );
    
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  entryId INTEGER,
  token TEXT,
  expiresAt DATETIME,
  accessLevel TEXT
);
`);

console.log('Migration completed.');

{
  "name": "no-code-prototype-backend",
  "version": "0.1.0",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "migrate": "node migrate.js",
    "seed": "node seed.js",
    "start:prod": "NODE_ENV=production node server.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "better-sqlite3": "^8.0.1",
    "cors": "^2.8.5",
    "body-parser": "^1.20.2",
    "jsonwebtoken": "^9.0.0",
    "bcryptjs": "^2.4.3",
    "uuid": "^9.0.0",
    "multer": "^1.4.5-lts.1"
  }
}
// Seed script
const Database = require('better-sqlite3');
const bcrypt = require('bcryptjs');
const db = new Database(process.env.DB_PATH || './data/app.db');

const hash = bcrypt.hashSync('password', 8);
db.prepare('INSERT OR IGNORE INTO users (id, email, fullName, passwordHash, role) VALUES (?,?,?,?,?)').run(1, 'karl@example.com', 'Karl-Heinz', hash, 'Admin');
db.prepare('INSERT OR IGNORE INTO projects (id, name, owner, description, tags) VALUES (?,?,?,?,?)').run(1, 'Demo Project', 1, 'Demo project', 'demo,testing');
db.prepare('INSERT OR IGNORE INTO entries (id, projectId, submittedBy, title, dataFields, numericMetric1, status) VALUES (?,?,?,?,?,?,?)')
  .run(1, 1, 1, 'First entry', JSON.stringify({field1:'value','notes':'sample'}), 42, 'Pending');


db.prepare('INSERT OR IGNORE INTO filehashes (id, entryId, filename, filepath, sha256) VALUES (?,?, ?,?,?)').run(1,1,'demo.txt','/uploads/demo.txt','');
    db.prepare('INSERT OR IGNORE INTO schemas (id, name, jsonschema) VALUES (?,?,?)').run(1,'default', JSON.stringify({fields:[{id:'title',label:'Title',type:'text'},{id:'dataFields',label:'Data (JSON)',type:'textarea'},{id:'numericMetric1',label:'Metric',type:'number'}]}));

console.log('Seeding done.');

// Minimal Express backend scaffold
const express = require('express');
const bodyParser = require('body-parser');
const cors = require('cors');
const Database = require('better-sqlite3');
const jwt = require('jsonwebtoken');
const bcrypt = require('bcryptjs');
const { v4: uuidv4 } = require('uuid');
const path = require('path');
const fs = require('fs');
const multer = require('multer');
const crypto = require('crypto');
const util = require('util');


const app = express();
app.use(cors());
app.use(bodyParser.json());

const DB_PATH = process.env.DB_PATH || './data/app.db';
const db = new Database(DB_PATH);

// Simple auth (demo only)
const JWT_SECRET = process.env.JWT_SECRET || 'dev-secret';

// Routes: health
app.get('/health', (req, res) => res.json({ status: 'ok' }));

// Auth (signup/login) - demo
app.post('/signup', (req, res) => {
  const { email, fullName, password } = req.body;
  if (!email || !password) return res.status(400).json({ error: 'email+password required' });
  const existing = db.prepare('SELECT * FROM users WHERE email = ?').get(email);
  if (existing) return res.status(400).json({ error: 'user exists' });
  const hash = bcrypt.hashSync(password, 8);
  const stmt = db.prepare('INSERT INTO users (email, fullName, passwordHash, role) VALUES (?,?,?,?)');
  const info = stmt.run(email, fullName || '', hash, 'Editor');
  const user = db.prepare('SELECT id, email, fullName, role FROM users WHERE id = ?').get(info.lastInsertRowid);
  const token = jwt.sign({ id: user.id, email: user.email }, JWT_SECRET, { expiresIn: '7d' });
  res.json({ user, token });
});

app.post('/login', (req, res) => {
  const { email, password } = req.body;
  if (!email || !password) return res.status(400).json({ error: 'email+password required' });
  const user = db.prepare('SELECT * FROM users WHERE email = ?').get(email);
  if (!user) return res.status(401).json({ error: 'invalid' });
  const ok = bcrypt.compareSync(password, user.passwordHash);
  if (!ok) return res.status(401).json({ error: 'invalid' });
  const token = jwt.sign({ id: user.id, email: user.email }, JWT_SECRET, { expiresIn: '7d' });
  res.json({ user: { id: user.id, email: user.email, fullName: user.fullName, role: user.role }, token });
});

// Middleware to check token
function auth(req, res, next){
  const h = req.headers.authorization;
  if (!h) return res.status(401).json({ error: 'no token' });
  const token = h.split(' ')[1];
  try {
    const payload = jwt.verify(token, JWT_SECRET);
    req.user = payload;
    next();
  } catch(e){
    return res.status(401).json({ error: 'invalid token' });
  }
}

// Entries CRUD (minimal)
app.get('/entries', auth, (req, res) => {
  const rows = db.prepare('SELECT * FROM entries ORDER BY createdAt DESC LIMIT 100').all();
  res.json(rows);
});

app.post('/entries', auth, (req, res) => {
  const { projectId, title, dataFields, numericMetric1 } = req.body;
  const stmt = db.prepare('INSERT INTO entries (projectId, submittedBy, title, dataFields, numericMetric1, status, createdAt) VALUES (?,?,?,?,?,?,datetime("now"))');
  const info = stmt.run(projectId || 1, req.user.id || 1, title || '', dataFields ? JSON.stringify(dataFields) : '{}', numericMetric1 || 0, 'Pending');
  const entry = db.prepare('SELECT * FROM entries WHERE id = ?').get(info.lastInsertRowid);
  // Stub: here you'd call an AI service or webhook
  res.json(entry);
});

// Simple summary endpoint that simulates AI (demo)
app.post('/ai/validate', auth, (req, res) => {
  const { record } = req.body;
  // Very simple rules-based check for demo
  const missing = [];
  if (!record.title) missing.push('title');
  let status = missing.length ? 'FLAGGED' : 'VALIDATED';
  const summary = (record.title || 'Untitled') + ' — auto summary (demo).';
  res.json({ status, missing_fields: missing, issues: [], summary });
});

// Serve frontend static in production
app.use('/uploads', express.static(path.join(__dirname, 'data', 'uploads')));
    app.use('/', express.static(path.join(__dirname, '../frontend/dist')));

const uploadsDir = path.join(__dirname, 'data', 'uploads');
fs.mkdirSync(uploadsDir, { recursive: true });
const writeFile = util.promisify(fs.writeFile);

const PORT = process.env.PORT || 4000;


// Create share token (auth required)
app.post('/share/create', auth, (req, res) => {
  const { entryId, expiresInHours, accessLevel } = req.body;
  const token = require('crypto').randomBytes(16).toString('hex');
  const expiresAt = new Date(Date.now() + ((expiresInHours||72) * 3600 * 1000)).toISOString();
  db.prepare('INSERT INTO sharinglinks (entryId, token, expiresAt, accessLevel) VALUES (?,?,?,?)').run(entryId, token, expiresAt, accessLevel || 'View');
  res.json({ ok:true, token, expiresAt });
});

// Public fetch by share token
app.get('/share/:token', (req, res) => {
  const token = req.params.token;
  const row = db.prepare('SELECT * FROM sharinglinks WHERE token = ?').get(token);
  if (!row) return res.status(404).json({ error: 'not found' });
  if (new Date(row.expiresAt) < new Date()) return res.status(410).json({ error: 'expired' });
  const entry = db.prepare('SELECT * FROM entries WHERE id = ?').get(row.entryId);
  res.json({ ok:true, entry });
});

// Entry CRUD: get by id, update, delete
app.get('/entries/:id', auth, (req, res) => {
  const id = req.params.id;
  const row = db.prepare('SELECT * FROM entries WHERE id = ?').get(id);
  if (!row) return res.status(404).json({ error: 'not found' });
  res.json({ ok:true, entry: row });
});

app.put('/entries/:id', auth, (req, res) => {
  const id = req.params.id;
  const { title, dataFields, numericMetric1, status } = req.body;
  const stmt = db.prepare('UPDATE entries SET title = ?, dataFields = ?, numericMetric1 = ?, status = ? WHERE id = ?');
  stmt.run(title, JSON.stringify(dataFields||{}), numericMetric1||0, status||'Pending', id);
  const row = db.prepare('SELECT * FROM entries WHERE id = ?').get(id);
  res.json({ ok:true, entry: row });
});

app.delete('/entries/:id', auth, (req, res) => {
  const id = req.params.id;
  db.prepare('DELETE FROM entries WHERE id = ?').run(id);
  res.json({ ok:true });
});

app.listen(PORT, () => console.log('Server running on port', PORT));



// Multer setup for file uploads (store in memory then write with hash)
const upload = multer({ storage: multer.memoryStorage(), limits: { fileSize: 50 * 1024 * 1024 } }); // 50MB

// Upload file and create entry (combined endpoint)
app.post('/entries/upload', auth, upload.single('file'), async (req, res) => {
  try {
    const file = req.file;
    const { projectId, title, dataFields, numericMetric1 } = req.body;
    let attachmentPath = null;
    let fileHash = null;
    if (file) {
      // compute SHA256
      const hash = crypto.createHash('sha256').update(file.buffer).digest('hex');
      const filename = Date.now() + '-' + file.originalname.replace(/[^a-zA-Z0-9.\-]/g,'_');
      const outPath = path.join(uploadsDir, filename);
      await writeFile(outPath, file.buffer);
      attachmentPath = '/uploads/' + filename;
      fileHash = hash;
    }
    const stmt = db.prepare('INSERT INTO entries (projectId, submittedBy, title, dataFields, numericMetric1, attachment, status, ai_summary, createdAt) VALUES (?,?,?,?,?,?,?,?,datetime("now"))');
    const info = stmt.run(projectId || 1, req.user.id || 1, title || '', dataFields ? JSON.stringify(JSON.parse(dataFields)) : '{}', numericMetric1 || 0, attachmentPath, 'Pending', null);
    const entry = db.prepare('SELECT * FROM entries WHERE id = ?').get(info.lastInsertRowid);
    // store file hash in a separate table
    if (fileHash) {
      db.prepare('INSERT INTO filehashes (entryId, filename, filepath, sha256, createdAt) VALUES (?,?,?,?,datetime("now"))').run(entry.id, file.originalname, attachmentPath, fileHash);
    }
    res.json({ ok:true, entry, fileHash });
  } catch (err) {
    console.error('Upload error', err);
    res.status(500).json({ error: 'upload failed', details: String(err) });
  }
});



// Admin: Save schema (simple, no auth level checks beyond auth middleware)
app.post('/admin/schema', auth, (req, res) => {
  const { name, jsonschema } = req.body;
  if (!name || !jsonschema) return res.status(400).json({ error: 'name + jsonschema required' });
  const stmt = db.prepare('INSERT INTO schemas (name, jsonschema) VALUES (?,?)');
  stmt.run(name, typeof jsonschema === 'string' ? jsonschema : JSON.stringify(jsonschema));
  res.json({ ok:true });
});
app.get('/admin/schema', auth, (req, res) => {
  const row = db.prepare('SELECT * FROM schemas ORDER BY createdAt DESC LIMIT 1').get();
  res.json({ ok:true, schema: row ? JSON.parse(row.jsonschema) : null });
});
ase and a frontend ready to deploy.
{
  "version": 2,
  "builds": [
    {
      "src": "functions/*.js",
      "use": "@vercel/node"
    },
    {
      "src": "frontend/package.json",
      "use": "@vercel/static-build"
    }
  ],
  "routes": [
    {
      "src": "/api/(.*)",
      "dest": "/functions/$1.js"
    },
    {
      "src": "/(.*)",
      "dest": "/frontend/$1"
    }
  ]
}
Quick start:
-- Supabase schema generated (edit as needed)
create extension if not exists pgcrypto;

CREATE TABLE IF NOT EXISTS users (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  email text UNIQUE NOT NULL,
  password_hash text NOT NULL,
  name text,
  created_at timestamptz DEFAULT now()
);

CREATE TABLE IF NOT EXISTS sessions (
  id uuid PRIMARY KEY,
  user_id uuid REFERENCES users(id),
  created_at timestamptz DEFAULT now()
);

CREATE TABLE IF NOT EXISTS entries (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id uuid REFERENCES users(id),
  title text,
  content text,
  metadata jsonb,
  created_at timestamptz DEFAULT now()
);

CREATE TABLE IF NOT EXISTS shares (
  id uuid PRIMARY KEY,
  entry_id uuid REFERENCES entries(id),
  owner_id uuid REFERENCES users(id),
  expires_at timestamptz,
  created_at timestamptz DEFAULT now()
);

CREATE INDEX IF NOT EXISTS idx_entries_user ON entries(user_id);
CREATE INDEX IF NOT EXISTS idx_shares_entry ON shares(entry_id);

1. Create a Supabase project (free) and run supabase_schema.sql in SQL editor.
2. Create a GitHub repo, push this folder.
3. In Netlify or Vercel, connect the repo.
   - Netlify: set Functions folder to `functions`
   - Vercel: functions will be detected automatically
4. Set environment variables from .env.example in Netlify/Vercel.
5. Deploy. Frontend will be available at yourapp.netlify.app or yourapp.vercel.app

Notes:
- For production-grade auth, use Supabase Auth instead of this simple sessions approach.
- Replace placeholder AI stub with actual OpenAI calls and set OPENAI_API_KEY.

   - Deploy site. You will get a netlify.app domain.
4) Verify[build]
  publish = "frontend/build"{
  "name": "recreated-app-functions",
  "version": "1.0.0",
  "dependencies": {
    "@supabase/supabase-js": "^2.1.0",
    "bcryptjs": "^2.4.3",
    "uuid": "^9.0.0"
  }
}
  functions = "functions"

[[redirects]]
  from = "/api/*"
  to = "/.netlify/functions/:splat"
  status = 200

   - Visit site URL, sign up a user, log in, create an entry, share it.

If you want me to run through these steps interactively (I cannot click deploy for you), I will produce the exact copy-paste values and commands.
